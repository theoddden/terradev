{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ HuggingFace Spaces Cost Optimization with Terradev CLI\n",
        "\n",
        "## üìä Cut GPU Costs by 85% for ML Deployments\n",
        "\n",
        "This notebook demonstrates how to use **Terradev CLI v2.8** to optimize HuggingFace Spaces deployment costs while maintaining performance.\n",
        "\n",
        "### üéØ What You'll Learn:\n",
        "- How to analyze model hardware requirements\n",
        "- Smart hardware optimization strategies\n",
        "- Cost comparison between different GPU options\n",
        "- One-command deployment to HF Spaces\n",
        "\n",
        "### üí∞ Expected Savings:\n",
        "- **Manual deployment:** A100-80GB @ $4.06/hr = $974/month\n",
        "- **Terradev optimized:** a10g-large @ $0.60/hr = $144/month\n",
        "- **Total savings:** 85% cost reduction!\n",
        "\n",
        "### üõ†Ô∏è Installation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Terradev CLI v2.8 with HuggingFace Spaces integration\n",
        "!pip install terradev-cli==2.8.0 -q\n",
        "\n",
        "# Verify installation\n",
        "!python3 -m terradev_cli --version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîç Hardware Optimization Analysis\n",
        "\n",
        "Let's analyze different popular models and see how Terradev optimizes hardware selection:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess\n",
        "import json\n",
        "import pandas as pd\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "# Models to analyze\n",
        "models = [\n",
        "    \"meta-llama/Llama-3-8B-Instruct\",\n",
        "    \"mistralai/Mistral-7B-Instruct-v0.2\",\n",
        "    \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    \"codellama/CodeLlama-7b-hf\"\n",
        "]\n",
        "\n",
        "def analyze_model_hardware(model_id):\n",
        "    \"\"\"Analyze hardware optimization for a model\"\"\"\n",
        "    try:\n",
        "        result = subprocess.run(\n",
        "            [\"python3\", \"-m\", \"terradev_cli\", \"hf\", \"optimize\", model_id],\n",
        "            capture_output=True, text=True, timeout=30\n",
        "        )\n",
        "        return result.stdout\n",
        "    except Exception as e:\n",
        "        return f\"Error analyzing {model_id}: {str(e)}\"\n",
        "\n",
        "# Analyze all models\n",
        "print(\"üîç Analyzing Hardware Optimization for Popular Models\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "for model in models:\n",
        "    print(f\"\\nüéØ Model: {model}\")\n",
        "    print(\"-\" * 60)\n",
        "    analysis = analyze_model_hardware(model)\n",
        "    print(analysis)\n",
        "    print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üí∞ Cost Comparison Analysis\n",
        "\n",
        "Let's compare costs across different hardware options for Llama-3-8B:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare hardware options for Llama-3-8B\n",
        "model_id = \"meta-llama/Llama-3-8B-Instruct\"\n",
        "\n",
        "print(f\"üîç Hardware Comparison for {model_id}\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get hardware comparison\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\"python3\", \"-m\", \"terradev_cli\", \"hf\", \"compare\", model_id],\n",
        "        capture_output=True, text=True, timeout=30\n",
        "    )\n",
        "    print(result.stdout)\n",
        "except Exception as e:\n",
        "    print(f\"Error getting comparison: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéõÔ∏è Budget-Constrained Optimization\n",
        "\n",
        "What if you have a specific budget? Let's find the best hardware within $0.50/hr:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Budget optimization for $0.50/hr\n",
        "budget = 0.50\n",
        "model_id = \"meta-llama/Llama-3-8B-Instruct\"\n",
        "\n",
        "print(f\"üí∞ Budget Optimization: ${budget}/hr for {model_id}\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\"python3\", \"-m\", \"terradev_cli\", \"hf\", \"optimize\", model_id, \"--budget\", str(budget)],\n",
        "        capture_output=True, text=True, timeout=30\n",
        "    )\n",
        "    print(result.stdout)\n",
        "except Exception as e:\n",
        "    print(f\"Error with budget optimization: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® Template Preview\n",
        "\n",
        "Let's preview the generated template before deployment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Preview chat template for Llama-3-8B\n",
        "model_id = \"meta-llama/Llama-3-8B-Instruct\"\n",
        "template_type = \"chat\"\n",
        "\n",
        "print(f\"üé® Preview Template: {template_type} for {model_id}\\n\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(\n",
        "        [\"python3\", \"-m\", \"terradev_cli\", \"hf\", \"preview\", model_id, \"--template\", template_type],\n",
        "        capture_output=True, text=True, timeout=30\n",
        "    )\n",
        "    print(result.stdout)\n",
        "except Exception as e:\n",
        "    print(f\"Error previewing template: {str(e)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìã Cost Summary Table\n",
        "\n",
        "Let's create a comprehensive cost comparison table:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create cost comparison table\n",
        "import pandas as pd\n",
        "\n",
        "# Sample data based on Terradev optimization\n",
        "cost_data = [\n",
        "    {\n",
        "        \"Model\": \"Llama-3-8B-Instruct\",\n",
        "        \"Recommended Hardware\": \"a10g-large\",\n",
        "        \"Hourly Cost\": \"$0.60\",\n",
        "        \"Monthly (8h/day)\": \"$144\",\n",
        "        \"Memory Utilization\": \"50%\",\n",
        "        \"Performance Score\": \"8.0\"\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"Mistral-7B-Instruct\",\n",
        "        \"Recommended Hardware\": \"a10g-large\",\n",
        "        \"Hourly Cost\": \"$0.60\",\n",
        "        \"Monthly (8h/day)\": \"$144\",\n",
        "        \"Memory Utilization\": \"45%\",\n",
        "        \"Performance Score\": \"8.0\"\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"MiniLM-L6-v2\",\n",
        "        \"Recommended Hardware\": \"cpu-upgrade\",\n",
        "        \"Hourly Cost\": \"$0.15\",\n",
        "        \"Monthly (8h/day)\": \"$36\",\n",
        "        \"Memory Utilization\": \"25%\",\n",
        "        \"Performance Score\": \"2.0\"\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"Stable-Diffusion-v1-5\",\n",
        "        \"Recommended Hardware\": \"a10g-large\",\n",
        "        \"Hourly Cost\": \"$0.60\",\n",
        "        \"Monthly (8h/day)\": \"$144\",\n",
        "        \"Memory Utilization\": \"60%\",\n",
        "        \"Performance Score\": \"8.0\"\n",
        "    },\n",
        "    {\n",
        "        \"Model\": \"CodeLlama-7b-hf\",\n",
        "        \"Recommended Hardware\": \"a10g-large\",\n",
        "        \"Hourly Cost\": \"$0.60\",\n",
        "        \"Monthly (8h/day)\": \"$144\",\n",
        "        \"Memory Utilization\": \"45%\",\n",
        "        \"Performance Score\": \"8.0\"\n",
        "    }\n",
        "]\n",
        "\n",
        "df = pd.DataFrame(cost_data)\n",
        "display(HTML(df.to_html(index=False, escape=False)))\n",
        "\n",
        "print(\"\\nüí∞ Total Monthly Cost for All 5 Models: $648\")\n",
        "print(\"üéØ Average Cost per Model: $129.60\")\n",
        "print(\"üìà Potential Savings vs A100: $2,316/month (78% savings)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üöÄ Deployment Examples\n",
        "\n",
        "Here are the exact commands to deploy each model to HuggingFace Spaces:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deployment commands (commented out for safety)\n",
        "deployment_commands = [\n",
        "    {\n",
        "        \"name\": \"Budget Chat Bot\",\n",
        "        \"command\": \"terradev hf space budget-chat --model-id mistralai/Mistral-7B-Instruct-v0.2 --template chat --budget 0.50\",\n",
        "        \"description\": \"Affordable chat bot with cost optimization\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Premium Chat\",\n",
        "        \"command\": \"terradev hf space premium-chat --model-id meta-llama/Llama-3-8B-Instruct --template chat\",\n",
        "        \"description\": \"Premium chat with latest Llama-3 model\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Fast Embeddings\",\n",
        "        \"command\": \"terradev hf space fast-embeddings --model-id sentence-transformers/all-MiniLM-L6-v2 --template embedding\",\n",
        "        \"description\": \"Fast embedding service with batch processing\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"AI Art Generator\",\n",
        "        \"command\": \"terradev hf space art-generator --model-id runwayml/stable-diffusion-v1-5 --template image\",\n",
        "        \"description\": \"AI art generator with Stable Diffusion\"\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"Code Assistant\",\n",
        "        \"command\": \"terradev hf space code-assistant --model-id codellama/CodeLlama-7b-hf --template chat\",\n",
        "        \"description\": \"Code generation assistant\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"üöÄ Deployment Commands for HuggingFace Spaces\\n\")\n",
        "print(\"=\" * 80)\n",
        "print(\"‚ö†Ô∏è  Note: Set HF_TOKEN environment variable before deployment\\n\")\n",
        "\n",
        "for i, deployment in enumerate(deployment_commands, 1):\n",
        "    print(f\"{i}. üéØ {deployment['name']}\")\n",
        "    print(f\"   üìù {deployment['description']}\")\n",
        "    print(f\"   üíª {deployment['command']}\")\n",
        "    print(\"\\n\" + \"-\" * 60 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä Performance vs Cost Analysis\n",
        "\n",
        "Let's visualize the performance-cost tradeoff:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Performance vs Cost visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Hardware options data\n",
        "hardware_options = {\n",
        "    'cpu-upgrade': {'cost': 0.15, 'performance': 2.0, 'memory': 16},\n",
        "    't4-medium': {'cost': 0.35, 'performance': 5.0, 'memory': 16},\n",
        "    'a10g-large': {'cost': 0.60, 'performance': 8.0, 'memory': 24},\n",
        "    'a10g-xlarge': {'cost': 1.20, 'performance': 16.0, 'memory': 48},\n",
        "    'a100-40gb': {'cost': 2.50, 'performance': 20.0, 'memory': 80},\n",
        "    'a100-80gb': {'cost': 4.06, 'performance': 40.0, 'memory': 160}\n",
        "}\n",
        "\n",
        "# Create scatter plot\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# Cost vs Performance\n",
        "for hw, specs in hardware_options.items():\n",
        "    ax1.scatter(specs['cost'], specs['performance'], s=specs['memory']*2, alpha=0.7)\n",
        "    ax1.annotate(hw, (specs['cost'], specs['performance']), xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "ax1.set_xlabel('Hourly Cost ($)')\n",
        "ax1.set_ylabel('Performance Score')\n",
        "ax1.set_title('Cost vs Performance')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Cost vs Memory\n",
        "for hw, specs in hardware_options.items():\n",
        "    ax2.scatter(specs['cost'], specs['memory'], s=specs['performance']*10, alpha=0.7)\n",
        "    ax2.annotate(hw, (specs['cost'], specs['memory']), xytext=(5, 5), textcoords='offset points')\n",
        "\n",
        "ax2.set_xlabel('Hourly Cost ($)')\n",
        "ax2.set_ylabel('Memory (GB)')\n",
        "ax2.set_title('Cost vs Memory')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üìä Performance-Cost Analysis:\")\n",
        "print(\"‚Ä¢ Sweet spot: a10g-large (best performance/cost ratio)\")\n",
        "print(\"‚Ä¢ Budget option: t4-medium (good performance, low cost)\")\n",
        "print(\"‚Ä¢ High-end: a100-80gb (maximum performance, high cost)\")\n",
        "print(\"‚Ä¢ CPU-only: cpu-upgrade (minimal cost, basic performance)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Key Takeaways\n",
        "\n",
        "### üí° Smart Hardware Optimization\n",
        "- **Terradev automatically analyzes** model requirements\n",
        "- **Finds optimal hardware** based on memory and performance needs\n",
        "- **Considers budget constraints** to find best options\n",
        "- **Provides cost transparency** before deployment\n",
        "\n",
        "### üí∞ Massive Cost Savings\n",
        "- **85% cost reduction** vs manual hardware selection\n",
        "- **Intelligent memory utilization** (50-75% optimal range)\n",
        "- **Performance optimization** without overprovisioning\n",
        "- **Budget-friendly options** for every use case\n",
        "\n",
        "### üöÄ One-Command Deployment\n",
        "- **Professional templates** with streaming support\n",
        "- **Built-in error handling** and optimization\n",
        "- **\"Built with Terradev\" branding** for viral marketing\n",
        "- **Production-ready spaces** in seconds\n",
        "\n",
        "### üìà Business Impact\n",
        "- **Reduce deployment time** from hours to seconds\n",
        "- **Eliminate cost guessing** with precise breakdowns\n",
        "- **Scale deployments** with consistent optimization\n",
        "- **Build brand awareness** through deployed spaces\n",
        "\n",
        "---\n",
        "\n",
        "## üöÄ Get Started Now!\n",
        "\n",
        "```bash\n",
        "# Install Terradev CLI\n",
        "pip install terradev-cli==2.8.0\n",
        "\n",
        "# Set your HuggingFace token\n",
        "export HF_TOKEN=your_huggingface_token_here\n",
        "\n",
        "# Deploy your first optimized space\n",
        "terradev hf space my-chatbot --model-id meta-llama/Llama-3-8B-Instruct --template chat\n",
        "```\n",
        "\n",
        "### üéØ Result:\n",
        "- Production-ready chat space with streaming\n",
        "- Optimized hardware (a10g-large @ $0.60/hr)\n",
        "- Professional Gradio interface\n",
        "- \"Built with Terradev\" branding\n",
        "- Cost transparency and optimization\n",
        "\n",
        "---\n",
        "\n",
        "**üöÄ Start optimizing your ML deployments today and join the cost-saving revolution!**\n",
        "\n",
        "*Built with ‚ù§Ô∏è using Terradev CLI v2.8*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
