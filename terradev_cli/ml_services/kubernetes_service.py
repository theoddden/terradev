#!/usr/bin/env python3
"""
Kubernetes Service Integration for Terradev
Manages Kubernetes clusters, Karpenter, and GPU node provisioning
"""

import os
import json
import asyncio
import aiohttp
import subprocess
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from pathlib import Path


@dataclass
class KubernetesConfig:
    """Kubernetes configuration"""
    kubeconfig_path: Optional[str] = None
    cluster_name: Optional[str] = None
    namespace: str = "default"
    karpenter_enabled: bool = False
    karpenter_version: str = "v0.32.0"
    aws_region: str = "us-east-1"
    aws_account_id: Optional[str] = None


class KubernetesService:
    """Kubernetes integration service for cluster management"""
    
    def __init__(self, config: KubernetesConfig):
        self.config = config
        self.session: Optional[aiohttp.ClientSession] = None
        
    async def __aenter__(self):
        self.session = aiohttp.ClientSession()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
    
    async def test_connection(self) -> Dict[str, Any]:
        """Test Kubernetes connection and get cluster info"""
        try:
            # Set kubeconfig path if provided
            env = os.environ.copy()
            if self.config.kubeconfig_path:
                env["KUBECONFIG"] = self.config.kubeconfig_path
            
            # Test kubectl connection
            result = subprocess.run(
                ["kubectl", "cluster-info"],
                capture_output=True,
                text=True,
                timeout=15,
                env=env
            )
            
            if result.returncode == 0:
                # Get cluster details
                cluster_info = result.stdout.strip()
                
                # Get node information
                nodes_result = subprocess.run(
                    ["kubectl", "get", "nodes", "-o", "json"],
                    capture_output=True,
                    text=True,
                    timeout=15,
                    env=env
                )
                
                nodes_info = []
                if nodes_result.returncode == 0:
                    try:
                        nodes_data = json.loads(nodes_result.stdout)
                        nodes_info = [
                            {
                                "name": node["metadata"]["name"],
                                "status": node["status"]["conditions"][-1]["type"] if node["status"].get("conditions") else "Unknown",
                                "version": node["status"].get("nodeInfo", {}).get("kubeletVersion", "Unknown"),
                                "os": node["status"].get("nodeInfo", {}).get("osImage", "Unknown")
                            }
                            for node in nodes_data.get("items", [])
                        ]
                    except json.JSONDecodeError:
                        pass
                
                return {
                    "status": "connected",
                    "cluster_name": self.config.cluster_name or "unknown",
                    "namespace": self.config.namespace,
                    "cluster_info": cluster_info,
                    "nodes": nodes_info,
                    "karpenter_enabled": self.config.karpenter_enabled
                }
            else:
                return {
                    "status": "failed",
                    "error": f"kubectl command failed: {result.stderr}"
                }
                
        except FileNotFoundError:
            return {
                "status": "failed",
                "error": "kubectl not found. Please install kubectl: https://kubernetes.io/docs/tasks/tools/"
            }
        except subprocess.TimeoutExpired:
            return {
                "status": "failed",
                "error": "kubectl command timed out. Check your cluster connection."
            }
        except Exception as e:
            return {
                "status": "failed",
                "error": str(e)
            }
    
    async def get_gpu_nodes(self) -> List[Dict[str, Any]]:
        """Get GPU-enabled nodes in the cluster"""
        try:
            env = os.environ.copy()
            if self.config.kubeconfig_path:
                env["KUBECONFIG"] = self.config.kubeconfig_path
            
            result = subprocess.run(
                ["kubectl", "get", "nodes", "-o", "json"],
                capture_output=True,
                text=True,
                timeout=15,
                env=env
            )
            
            if result.returncode != 0:
                raise Exception(f"Failed to get nodes: {result.stderr}")
            
            nodes_data = json.loads(result.stdout)
            gpu_nodes = []
            
            for node in nodes_data.get("items", []):
                # Check for GPU labels or taints
                labels = node.get("metadata", {}).get("labels", {})
                taints = node.get("spec", {}).get("taints", [])
                
                has_gpu = (
                    "accelerator" in labels.get("node.kubernetes.io/instance-type", "").lower() or
                    "nvidia.com/gpu" in node.get("status", {}).get("capacity", {}) or
                    any("gpu" in str(taint).lower() for taint in taints)
                )
                
                if has_gpu:
                    gpu_nodes.append({
                        "name": node["metadata"]["name"],
                        "status": node["status"].get("conditions", [{}])[-1].get("type", "Unknown"),
                        "gpu_capacity": node.get("status", {}).get("capacity", {}).get("nvidia.com/gpu", "0"),
                        "instance_type": labels.get("node.kubernetes.io/instance-type", "Unknown"),
                        "labels": labels,
                        "taints": taints
                    })
            
            return gpu_nodes
            
        except Exception as e:
            raise Exception(f"Failed to get GPU nodes: {e}")
    
    async def install_karpenter(self) -> Dict[str, Any]:
        """Install Karpenter for automatic node provisioning"""
        if not self.config.karpenter_enabled:
            return {
                "status": "failed",
                "error": "Karpenter is not enabled in configuration"
            }
        
        try:
            env = os.environ.copy()
            if self.config.kubeconfig_path:
                env["KUBECONFIG"] = self.config.kubeconfig_path
            
            # Create namespace
            namespace_cmd = ["kubectl", "create", "namespace", "karpenter", "--dry-run=client", "-o", "yaml"]
            result = subprocess.run(namespace_cmd, capture_output=True, text=True, timeout=10, env=env)
            
            if result.returncode == 0:
                apply_result = subprocess.run(
                    ["kubectl", "apply", "-f", "-"],
                    input=result.stdout,
                    text=True,
                    timeout=10,
                    env=env
                )
            
            # Install Karpenter via Helm (simplified version)
            helm_cmd = [
                "helm", "upgrade", "--install", "karpenter",
                "oci://public.ecr.aws/karpenter/karpenter",
                f"--version={self.config.karpenter_version}",
                "--namespace=karpenter",
                f"--set=settings.clusterName={self.config.cluster_name or 'default'}",
                f"--set=settings.interruptionQueue={self.config.cluster_name or 'default'}",
                "--wait"
            ]
            
            result = subprocess.run(
                helm_cmd,
                capture_output=True,
                text=True,
                timeout=300,
                env=env
            )
            
            if result.returncode == 0:
                return {
                    "status": "installed",
                    "version": self.config.karpenter_version,
                    "output": result.stdout
                }
            else:
                raise Exception(f"Helm installation failed: {result.stderr}")
                
        except FileNotFoundError as e:
            if "helm" in str(e):
                return {
                    "status": "failed",
                    "error": "Helm not found. Please install Helm: https://helm.sh/docs/intro/install/"
                }
            else:
                raise Exception(f"Command not found: {e}")
        except Exception as e:
            return {
                "status": "failed",
                "error": str(e)
            }
    
    async def create_karpenter_provisioner(self, gpu_type: str, limits: Dict[str, Any]) -> Dict[str, Any]:
        """Create Karpenter provisioner for GPU nodes"""
        try:
            env = os.environ.copy()
            if self.config.kubeconfig_path:
                env["KUBECONFIG"] = self.config.kubeconfig_path
            
            # Generate provisioner YAML
            provisioner_yaml = f"""
apiVersion: karpenter.sh/v1beta1
kind: Provisioner
metadata:
  name: gpu-{gpu_type.lower()}
spec:
  requirements:
  - key: karpenter.k8s.aws/instance-category
    operator: In
    values: ["g"]
  - key: kubernetes.io/arch
    operator: In
    values: ["amd64"]
  - key: kubernetes.io/os
    operator: In
    values: ["linux"]
  - key: karpenter.k8s.aws/instance-family
    operator: In
    values: ["p5", "p4", "p3", "g5", "g4"]
  - key: kubernetes.io/arch
    operator: In
    values: ["amd64"]
  - key: karpenter/capacity-type
    operator: In
    values: ["on-demand", "spot"]
  - key: kubernetes.io/arch
    operator: In
    values: ["amd64"]
  limits:
    resources:
      cpu: {limits.get('cpu', '1000')}
      memory: {limits.get('memory', '1000Gi')}
  providerRef:
    name: default
  ttlSecondsAfterEmpty: 300
  consolidation:
    enabled: true
"""
            
            # Apply provisioner
            result = subprocess.run(
                ["kubectl", "apply", "-f", "-"],
                input=provisioner_yaml,
                text=True,
                timeout=30,
                env=env
            )
            
            if result.returncode == 0:
                return {
                    "status": "created",
                    "provisioner": f"gpu-{gpu_type.lower()}",
                    "output": result.stdout
                }
            else:
                raise Exception(f"Failed to create provisioner: {result.stderr}")
                
        except Exception as e:
            return {
                "status": "failed",
                "error": str(e)
            }
    
    async def get_cluster_resources(self) -> Dict[str, Any]:
        """Get cluster resource information"""
        try:
            env = os.environ.copy()
            if self.config.kubeconfig_path:
                env["KUBECONFIG"] = self.config.kubeconfig_path
            
            # Get nodes with resource info
            result = subprocess.run(
                ["kubectl", "top", "nodes", "--no-headers"],
                capture_output=True,
                text=True,
                timeout=15,
                env=env
            )
            
            resources = {
                "total_cpu": 0,
                "total_memory": 0,
                "total_gpu": 0,
                "nodes": []
            }
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        parts = line.split()
                        if len(parts) >= 3:
                            node_name = parts[0]
                            cpu_cores = parts[1].replace('m', '')
                            memory = parts[2].replace('Mi', '')
                            
                            try:
                                cpu_int = int(cpu_cores) / 1000 if cpu_cores.endswith('m') else int(cpu_cores)
                                mem_gb = int(memory) / 1024
                                
                                resources["nodes"].append({
                                    "name": node_name,
                                    "cpu_cores": cpu_int,
                                    "memory_gb": mem_gb
                                })
                                
                                resources["total_cpu"] += cpu_int
                                resources["total_memory"] += mem_gb
                            except ValueError:
                                continue
            
            # Get GPU resources
            gpu_result = subprocess.run(
                ["kubectl", "get", "nodes", "-o", "jsonpath='{range .items[*]}{.metadata.name}{\" \"}{.status.capacity.nvidia.com/gpu}{\"\\n\"}{end}'"],
                capture_output=True,
                text=True,
                timeout=15,
                env=env
            )
            
            if gpu_result.returncode == 0:
                for line in gpu_result.stdout.strip().split('\n'):
                    if line.strip():
                        parts = line.split()
                        if len(parts) >= 2:
                            try:
                                gpu_count = int(parts[1])
                                resources["total_gpu"] += gpu_count
                            except ValueError:
                                continue
            
            return resources
            
        except Exception as e:
            raise Exception(f"Failed to get cluster resources: {e}")
    
    def get_kubernetes_config(self) -> Dict[str, str]:
        """Get Kubernetes configuration for environment variables"""
        config = {}
        
        if self.config.kubeconfig_path:
            config["KUBECONFIG"] = self.config.kubeconfig_path
            
        if self.config.cluster_name:
            config["KUBERNETES_CLUSTER_NAME"] = self.config.cluster_name
            
        if self.config.namespace:
            config["KUBERNETES_NAMESPACE"] = self.config.namespace
            
        if self.config.aws_region:
            config["AWS_DEFAULT_REGION"] = self.config.aws_region
            
        return config


def create_kubernetes_service_from_credentials(credentials: Dict[str, str]) -> KubernetesService:
    """Create KubernetesService from credential dictionary"""
    config = KubernetesConfig(
        kubeconfig_path=credentials.get("kubeconfig_path"),
        cluster_name=credentials.get("cluster_name"),
        namespace=credentials.get("namespace", "default"),
        karpenter_enabled=credentials.get("karpenter_enabled", "false").lower() == "true",
        karpenter_version=credentials.get("karpenter_version", "v0.32.0"),
        aws_region=credentials.get("aws_region", "us-east-1"),
        aws_account_id=credentials.get("aws_account_id")
    )
    
    return KubernetesService(config)


def get_kubernetes_setup_instructions() -> str:
    """Get setup instructions for Kubernetes"""
    return """
ğŸš€ Kubernetes Setup Instructions:

1. Install kubectl:
   # macOS
   brew install kubectl
   
   # Linux
   curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
   sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl
   
   # Windows (using Chocolatey)
   choco install kubernetes-cli

2. Install Helm (for Karpenter):
   # macOS
   brew install helm
   
   # Linux
   curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
   
   # Windows
   choco install kubernetes-helm

3. Configure kubectl to connect to your cluster:
   # For EKS
   aws eks update-kubeconfig --region us-east-1 --name your-cluster-name
   
   # For other clusters, use your provider's CLI tools

4. Test the connection:
   kubectl cluster-info
   kubectl get nodes

5. Configure Terradev with your Kubernetes credentials:
   terradev configure --provider kubernetes --cluster-name your-cluster --kubeconfig-path ~/.kube/config

ğŸ“‹ Required Credentials:
- kubeconfig_path: Path to Kubernetes config file (optional, uses default)
- cluster_name: Kubernetes cluster name (optional)
- namespace: Kubernetes namespace (default: "default")
- karpenter_enabled: Enable Karpenter (default: "false")
- karpenter_version: Karpenter version (default: "v0.32.0")
- aws_region: AWS region (default: "us-east-1")
- aws_account_id: AWS account ID (optional)

ğŸ’¡ Usage Examples:
# Test connection
terradev ml kubernetes --test

# Get GPU nodes
terradev ml kubernetes --gpu-nodes

# Install Karpenter
terradev ml kubernetes --install-karpenter

# Create GPU provisioner
terradev ml kubernetes --create-provisioner --gpu-type A100 --cpu-limit 100 --memory-limit 1000Gi

# Get cluster resources
terradev ml kubernetes --resources

ğŸ”— Integration with Terradev:
Kubernetes can be used alongside Terradev's provisioning:
- Provision GPU instances with Terradev
- Add them to Kubernetes cluster
- Use Karpenter for automatic scaling
- Deploy ML workloads with KServe

ğŸ³ Local Kubernetes:
# Minikube (for testing)
minikube start --driver=docker --cpus=8 --memory=16g --gpus=all

# Kind (for testing)
kind create cluster --config kind-config.yaml

â˜¸ï¸ Karpenter Integration:
Karpenter automatically provisions nodes based on workload demands:
- GPU workloads trigger GPU node provisioning
- Cost optimization with spot instances
- Automatic scaling and consolidation
- Integration with Terradev's cost tracking

ğŸ“ Example Workflow:
# 1. Configure Kubernetes
terradev configure --provider kubernetes --cluster-name ml-cluster

# 2. Test connection
terradev ml kubernetes --test

# 3. Install Karpenter
terradev ml kubernetes --install-karpenter

# 4. Create GPU provisioner
terradev ml kubernetes --create-provisioner --gpu-type A100

# 5. Deploy GPU workloads
kubectl apply -f gpu-workload.yaml

# 6. Monitor node provisioning
kubectl get nodes -w
"""
