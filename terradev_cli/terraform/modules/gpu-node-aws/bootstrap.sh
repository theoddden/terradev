#!/bin/bash
# AWS GPU Node Bootstrap Script

set -e

# Variables
CLUSTER_NAME="${cluster_name}"
TAILSCALE_AUTHKEY="${tailscale_authkey}"
K8S_JOIN_SCRIPT="${k8s_join_script}"
GPU_TYPE="${gpu_type}"
PROVIDER="${provider}"

# Labels
LABELS="${labels}"

echo "ðŸš€ Bootstrapping AWS GPU Node for ${CLUSTER_NAME}"
echo "ðŸŽ® GPU Type: ${GPU_TYPE}"
echo "ðŸ·ï¸  Provider: ${PROVIDER}"

# Update system
echo "ðŸ“¦ Updating system packages..."
apt-get update && apt-get upgrade -y

# Install required packages
echo "ðŸ“¦ Installing required packages..."
apt-get install -y \
    curl \
    wget \
    gnupg \
    software-properties-common \
    ca-certificates \
    apt-transport-https \
    htop \
    git \
    vim \
    jq \
    awscli

# Install NVIDIA drivers (if not already installed)
echo "ðŸŽ® Installing NVIDIA drivers..."
if ! command -v nvidia-smi &> /dev/null; then
    wget -O /tmp/nvidia-driver.run https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
    dpkg -i /tmp/nvidia-driver.run
    apt-get update
    apt-get install -y cuda-toolkit-12-2 cuda-drivers
else
    echo "NVIDIA drivers already installed"
fi

# Install Docker
echo "ðŸ³ Installing Docker..."
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
apt-get update
apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Configure Docker for NVIDIA
echo "âš™ï¸  Configuring Docker for NVIDIA..."
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/nvidia-docker/gpgkey | apt-key add -
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | tee /etc/apt/sources.list.d/nvidia-docker.list
apt-get update && apt-get install -y nvidia-docker2
systemctl restart docker

# Install Kubernetes components
echo "â˜¸ï¸  Installing Kubernetes components..."
curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.28/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
echo 'deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.28/deb/ /' | tee /etc/apt/sources.list.d/kubernetes.list
apt-get update
apt-get install -y kubelet kubeadm kubectl
apt-mark hold kubelet kubeadm kubectl

# Install Tailscale
echo "ðŸ”— Installing Tailscale..."
curl -fsSL https://tailscale.com/install.sh | sh

# Start and enable Tailscale
echo "ðŸ”— Starting Tailscale..."
tailscale up --authkey="${TAILSCALE_AUTHKEY}" --hostname="${CLUSTER_NAME}-aws-node" --advertise-routes=10.0.0.0/24 --accept-routes

# Wait for Tailscale to be ready
echo "â³ Waiting for Tailscale to be ready..."
while ! tailscale status | grep -q "Connected"; do
    echo "Waiting for Tailscale connection..."
    sleep 5
done

# Get Tailscale IP
TAILSCALE_IP=$(tailscale ip -4)
echo "ðŸ”— Tailscale IP: ${TAILSCALE_IP}"

# Configure Kubernetes
echo "âš™ï¸  Configuring Kubernetes..."
cat > /etc/docker/daemon.json <<EOF
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF

mkdir -p /etc/systemd/system/docker.service.d
cat > /etc/systemd/system/docker.service.d/override.conf <<EOF
[Service]
ExecStart=
ExecStart=/usr/bin/dockerd
EOF

systemctl daemon-reload
systemctl restart docker
systemctl enable docker

# Disable swap
echo "ðŸ’¾ Disabling swap..."
swapoff -a
sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab

# Enable kernel modules
echo "ðŸ”§ Enabling kernel modules..."
cat > /etc/modules-load.d/k8s.conf <<EOF
br_netfilter
overlay
EOF

modprobe br_netfilter
modprobe overlay

# Set sysctl parameters
echo "âš™ï¸  Setting sysctl parameters..."
cat > /etc/sysctl.d/k8s.conf <<EOF
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

sysctl --system

# Mount additional storage
echo "ðŸ’¾ Mounting additional storage..."
mkfs -t ext4 /dev/sdc
mkdir -data
mount /dev/sdc /data
echo '/dev/sdc /data ext4 defaults 0 0' >> /etc/fstab

# Join Kubernetes cluster
if [ -n "$K8S_JOIN_SCRIPT" ] && [ -f "$K8S_JOIN_SCRIPT" ]; then
    echo "â˜¸ï¸  Joining Kubernetes cluster..."
    bash "$K8S_JOIN_SCRIPT"
    
    # Wait for node to be ready
    echo "â³ Waiting for node to be ready..."
    while ! kubectl get nodes | grep -q "$(hostname)"; do
        echo "Waiting for node registration..."
        sleep 10
    done
    
    # Apply labels
    echo "ðŸ·ï¸  Applying labels..."
    kubectl label node $(hostname) ${LABELS} --overwrite
    
    # Apply GPU taint
    kubectl taint node $(hostname) nvidia.com/gpu=true:NoSchedule --overwrite
else
    echo "âš ï¸  No Kubernetes join script provided, skipping cluster join"
fi

# Install NVIDIA device plugin
echo "ðŸŽ® Installing NVIDIA device plugin..."
kubectl apply -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.14.0/nvidia-device-plugin.yml

# Test GPU
echo "ðŸ§ª Testing GPU..."
nvidia-smi

# Create GPU test script
cat > /usr/local/bin/test-gpu.sh <<'EOF'
#!/bin/bash
echo "ðŸŽ® GPU Test Results:"
nvidia-smi
echo ""
echo "ðŸ³ Docker GPU Test:"
docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi
echo ""
echo "â˜¸ï¸  Kubernetes GPU Test:"
kubectl get nodes -L nvidia.com/gpu
echo ""
echo "ðŸ’¾ Storage Test:"
df -h /data
EOF

chmod +x /usr/local/bin/test-gpu.sh

# Create status script
cat > /usr/local/bin/status.sh <<'EOF'
#!/bin/bash
echo "ðŸš€ Terradev GPU Node Status"
echo "=========================="
echo "ðŸ”— Tailscale Status:"
tailscale status
echo ""
echo "ðŸŽ® GPU Status:"
nvidia-smi
echo ""
echo "ðŸ³ Docker Status:"
systemctl status docker --no-pager -l
echo ""
echo "â˜¸ï¸  Kubernetes Status:"
if command -v kubectl &> /dev/null; then
    kubectl get nodes -o wide
    kubectl get pods -A
else
    echo "Kubernetes not configured"
fi
echo ""
echo "ðŸ’¾ Storage Status:"
df -h /data
echo ""
echo "ðŸŒ AWS Metadata:"
curl -s http://169.254.169.254/latest/meta-data/instance-id
curl -s http://169.254.169.254/latest/meta-data/instance-type
curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone
EOF

chmod +x /usr/local/bin/status.sh

# Create cleanup script
cat > /usr/local/bin/cleanup.sh <<'EOF'
#!/bin/bash
echo "ðŸ§¹ Cleaning up GPU node..."
# Leave Kubernetes cluster
if command -v kubectl &> /dev/null; then
    kubectl drain $(hostname) --ignore-daemonsets --delete-emptydir-data --force
    kubectl delete node $(hostname)
fi
# Leave Tailscale
tailscale down
# Stop services
systemctl stop kubelet docker
echo "âœ… Cleanup complete"
EOF

chmod +x /usr/local/bin/cleanup.sh

# Configure AWS IAM role for node
echo "ðŸ”§ Configuring AWS IAM role..."
if command -v aws &> /dev/null; then
    # Get instance metadata
    INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
    REGION=$(curl -s http://169.254.169.254/latest/meta-data/placement/availability-zone | sed 's/[a-z]$//')
    
    echo "Instance ID: $INSTANCE_ID"
    echo "Region: $REGION"
    
    # Configure AWS CLI
    aws configure set default.region $REGION
else
    echo "AWS CLI not available"
fi

echo "âœ… Bootstrap complete!"
echo "ðŸŽ® GPU: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits)"
echo "ðŸ”— Tailscale IP: ${TAILSCALE_IP}"
echo "â˜¸ï¸  Kubernetes: $(command -v kubectl &> /dev/null && echo 'Configured' || echo 'Not configured')"
echo "ðŸ’¾ Storage: $(df -h /data | tail -1 | awk '{print $2}')"
echo ""
echo "ðŸ“Š Run 'status.sh' for detailed status"
echo "ðŸ§ª Run 'test-gpu.sh' to test GPU functionality"
echo "ðŸ§¹ Run 'cleanup.sh' to clean up node"
