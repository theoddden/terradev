# ğŸš€ Terradev GPU Cloud â€” OpenClaw Skill

**Cross-cloud GPU provisioning, K8s clusters, and inference overflow for OpenClaw agents.**

Your local GPU maxed out? One command to burst to cloud. Need a K8s cluster with H100s? Done. Want real-time pricing across 11+ providers? Instant.

## What This Skill Does

| Capability | Example |
|-----------|---------|
| **GPU Price Quotes** | "Find me the cheapest H100 right now" |
| **Multi-Cloud Provisioning** | "Spin up 4 A100s across the cheapest clouds" |
| **K8s GPU Clusters** | "Create a Kubernetes cluster with 8 H100 nodes" |
| **Inference Deployment** | "Deploy Llama 2 to a serverless endpoint" |
| **HuggingFace Spaces** | "Share my model on HuggingFace with one click" |
| **GPU Overflow** | "My local GPU is full, burst this job to cloud" |
| **Instance Management** | "Show me all running instances and costs" |
| **Cost Optimization** | "Find cheaper alternatives for my running GPUs" |

## Install

### Via ClawHub
```bash
clawhub install terradev-gpu-cloud
```

### Manual
```bash
# 1. Install Terradev CLI
pip install terradev-cli

# 2. Configure at least one provider
terradev setup runpod --quick
terradev configure --provider runpod

# 3. Copy the skill folder to your OpenClaw skills directory
cp -r terradev-gpu-cloud ~/.openclaw/skills/
```

## Demo

```
You: "Find me the cheapest H100 right now"

ğŸ” Querying 11 providers in parallel...

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Provider     â”‚ GPU      â”‚ Price/hr â”‚ Region â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ RunPod       â”‚ H100 80G â”‚ $1.89    â”‚ US-TX  â”‚
â”‚ Lambda Labs  â”‚ H100 80G â”‚ $1.99    â”‚ US-TX  â”‚
â”‚ Vast.ai      â”‚ H100 80G â”‚ $2.15    â”‚ US-OR  â”‚
â”‚ CoreWeave    â”‚ H100 80G â”‚ $2.49    â”‚ US-NJ  â”‚
â”‚ TensorDock   â”‚ H100 80G â”‚ $2.79    â”‚ US-TX  â”‚
â”‚ AWS (spot)   â”‚ p5.xlg   â”‚ $3.21    â”‚ us-e-1 â”‚
â”‚ GCP (spot)   â”‚ a3-high  â”‚ $3.89    â”‚ us-c-1 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ’° Best price: RunPod H100 @ $1.89/hr (47% cheaper than AWS)
```

```
You: "Create a K8s cluster with 4 H100s for training"

ğŸ”§ Creating multi-cloud GPU cluster...
   â”œâ”€â”€ Karpenter NodeClass: spot-first H100 scheduling
   â”œâ”€â”€ KEDA autoscaling: 90% GPU utilization trigger
   â”œâ”€â”€ CNI ordering: EKS v21 race condition handled
   â””â”€â”€ Node pools: RunPod + Lambda (cheapest spots)

âœ… Cluster 'training-cluster' ready in 47 seconds
   4x H100 80GB @ $1.89/hr avg = $7.56/hr total
```

```
You: "My RTX 4090 is maxed out running inference, overflow to cloud"

ğŸ“Š Local GPU: RTX 4090 24GB â€” 98% utilized
ğŸŒŠ Overflow strategy: Burst to cloud A10G (similar VRAM, $0.76/hr)

terradev provision -g A10G -n 2 --parallel 6

âœ… 2x A10G provisioned on Vast.ai @ $0.76/hr
   Endpoint: ssh root@<ip> -p 22
   Run: terradev execute -i <id> -c "python serve.py"
```

## BYOAPI â€” Your Keys Stay Local

Terradev never touches, stores, or proxies your cloud credentials through a third party.

- `terradev configure --provider <name>` â†’ keys stored in `~/.terradev/credentials.json`
- Every API call goes directly from your machine to the cloud provider
- No middleman, no shared credentials, no markup on pricing
- Enterprise-ready: SOC2/HIPAA compliant credential handling

## Supported Providers

RunPod Â· Vast.ai Â· AWS Â· GCP Â· Azure Â· Lambda Labs Â· CoreWeave Â· TensorDock Â· Oracle Cloud Â· Crusoe Cloud Â· DigitalOcean Â· HyperStack

## Links

- **Terradev CLI**: https://github.com/theoddden/Terradev
- **PyPI**: https://pypi.org/project/terradev-cli/
- **Docs**: https://theodden.github.io/Terradev/

## License

Business Source License 1.1 (BUSL-1.1)
