# SkyPilot Task YAML Example for Terradev Wrapper
# This file demonstrates how to structure tasks for the Terradev wrapper

resources:
  # GPU requirements - SkyPilot will find the cheapest option
  accelerators: A100:1  # or A100:4, H100:1, etc.
  
  # Cloud provider selection (optional - let SkyPilot decide)
  cloud: any  # or aws, gcp, azure, runpod, lambda, coreweave
  
  # Instance type (optional - SkyPilot will optimize)
  instance_type: any
  
  # Region preferences (optional)
  # region: us-east-1,us-west-2
  
  # Spot instance preference
  use_spot: true
  
  # Resource requirements
  cpu: 8
  memory: 32+
  
# Working directory - will be synced to the cluster
workdir: ~/ml-workspace

# Setup commands - run before the main task
setup: |
  # Install dependencies
  pip install torch torchvision transformers
  
  # Download models/data
  python download_models.py
  
  # Setup environment
  export CUDA_VISIBLE_DEVICES=0
  export PYTHONPATH=$PYTHONPATH:~/ml-workspace

# Main task commands
run: |
  echo "ðŸš€ Starting ML training with Terradev optimization"
  
  # Display deployment info (provided by Terradev)
  echo "Provider: $TERRADEV_PROVIDER"
  echo "GPU Type: $TERRADEV_GPU_TYPE"
  echo "Region: $TERRADEV_REGION"
  echo "Latency Score: $TERRADEV_LATENCY_SCORE"
  echo "Arbitrage Confidence: $TERRADEV_CONFIDENCE"
  
  # Run the main training script
  python train.py \
    --model resnet50 \
    --epochs 50 \
    --batch-size 32 \
    --data-dir ~/ml-workspace/data \
    --output-dir ~/ml-workspace/outputs
  
  # Upload results to attribution storage
  python upload_results.py \
    --deployment-id $TERRADEV_DEPLOYMENT_ID \
    --team-id $TERRADEV_TEAM_ID \
    --project-id $TERRADEV_PROJECT_ID

# Environment variables
envs:
  # Terradev will inject these automatically
  TERRADEV_PROVIDER: ""
  TERRADEV_GPU_TYPE: ""
  TERRADEV_REGION: ""
  TERRADEV_DEPLOYMENT_ID: ""
  TERRADEV_TEAM_ID: ""
  TERRADEV_PROJECT_ID: ""
  TERRADEV_LATENCY_SCORE: ""
  TERRADEV_CONFIDENCE: ""
  
  # Custom environment variables
  PYTHONPATH: "/home/sky_user/ml-workspace"
  TOKENIZERS_PARALLELISM: "false"

# File mounts (optional)
# file_mounts:
#   /data: ~/my-dataset/
#   /models: ~/pretrained-models/

# Service configuration (optional - for serving)
# service:
#   port: 8080
#   readiness_probe:
#     path: /health
#     initial_delay_seconds: 30
